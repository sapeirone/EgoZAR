{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egocentric zone-aware action recognition across environments\n",
    "\n",
    "This notebook is meant to run on Google Colab.\n",
    "\n",
    "**NOTE**: results in the paper were averaged over three runs with different seeds so results may vary slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "\n",
    "Install the missing dependencies on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install coloredlogs wandb tqdm einops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the code\n",
    "\n",
    "Download the EgoZAR codebase and the required annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sapeirone/EgoZAR.git\n",
    "!git clone https://github.com/epic-kitchens/epic-kitchens-100-annotations.git\n",
    "!mv epic-kitchens-100-annotations/UDA_annotations EgoZAR/annotations\n",
    "!rm -r epic-kitchens-100-annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EK100 UDA TBN features\n",
    "Download the official TBN features from [here](https://github.com/epic-kitchens/C4-UDA-for-Action-Recognition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p data\n",
    "\n",
    "wget -O ek100.zip https://www.dropbox.com/scl/fo/us8zy3r2rufqriig0pbii/ABeUdV83UNmJ5US-oCxAPno?rlkey=yzbuczl198z067pnotx1zxvuo&e=1&dl=0\n",
    "\n",
    "unzip ek100.zip -d data/\n",
    "\n",
    "rm ek100.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP features\n",
    "\n",
    "Download the pre-extracted CLIP ViT-L/14 features for EgoZAR. \n",
    "\n",
    "You can also extract these features with different CLIP variants using the `save_CLIP_features.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd EgoZAR\n",
    "\n",
    "mkdir clip_features\n",
    "\n",
    "# Souce train features\n",
    "gdown 1TBmxIuoERx1v1xkrBfNfvWeIHNYUzRZS\n",
    "\n",
    "# Target validation features\n",
    "gdown 186X1PBb1RuzBeXObbCs60DEaJJ4vlLdg\n",
    "\n",
    "mv ViT* clip_features/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Only baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --modality=RGB --modality=Flow --modality=Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EgoZAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --modality=RGB --modality=Flow --modality=Audio --ca --use-input-features=N --use-egozar-motion-features=Y --use-egozar-acz-features=Y \\\n",
    "    --disent-loss-weight=1.0 \\\n",
    "    --disent-n-clusters=4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ego-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
